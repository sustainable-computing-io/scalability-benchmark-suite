{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_timestamp_file(results_dir):\n",
    "    timestamp_df = pd.read_csv(os.path.join(results_dir, 'timestamps.csv'))\n",
    "    independent_variable = timestamp_df.columns[0]\n",
    "    independent_variable_values = list(timestamp_df[independent_variable])\n",
    "\n",
    "    # Create time intervals\n",
    "    timestamp_df['Start time'] = timestamp_df['Start time'].apply(datetime.fromtimestamp)\n",
    "    timestamp_df['End time'] = timestamp_df['End time'].apply(datetime.fromtimestamp)\n",
    "    intervals = pd.IntervalIndex.from_arrays(timestamp_df['Start time'], timestamp_df['End time'])\n",
    "\n",
    "    return independent_variable, independent_variable_values, intervals\n",
    "\n",
    "def read_metric_file(results_dir, file_name):\n",
    "    metric = os.path.splitext(file_name)[0]\n",
    "    file_path = os.path.join(results_dir, file_name)\n",
    "    if os.stat(file_path).st_size == 0:\n",
    "        print(file_path, 'is empty. Skipping...')\n",
    "        return None\n",
    "    metric_df = pd.read_json(file_path)\n",
    "    metric_df.columns = ['Timestamp', metric]\n",
    "\n",
    "    # Convert units of metric columns\n",
    "    if 'cpu'in metric:\n",
    "        metric_df[metric] = metric_df[metric] * 100 # Convert to %\n",
    "    elif 'network' in metric:\n",
    "        metric_df[metric] = metric_df[metric] / 1024 # Convert B/s to KiB/s\n",
    "    elif 'memory' in metric:\n",
    "        metric_df[metric] = metric_df[metric] / 1048576 # Convert B to MiB\n",
    "    return metric_df\n",
    "\n",
    "def read_experiment(results_dir, skip_memory=True):\n",
    "    # Process timestamps file\n",
    "    independent_variable, independent_variable_values, timestamp_intervals = process_timestamp_file(results_dir)\n",
    "    \n",
    "    df = None\n",
    "    for file_name in os.listdir(results_dir):\n",
    "        if file_name != 'timestamps.csv' and (not 'memory' in file_name or not skip_memory):\n",
    "            metric_df = read_metric_file(results_dir, file_name)\n",
    "            if metric_df is None:\n",
    "                continue\n",
    "\n",
    "            if df is None:\n",
    "                df = metric_df\n",
    "            else:\n",
    "                df = df.merge(metric_df)\n",
    "    \n",
    "    # Assign metric samples to their corresponding timestamp intervals they were collected during\n",
    "    df['Timestamp'] = df['Timestamp'].apply(datetime.fromtimestamp)\n",
    "    df['Time interval'] = pd.cut(df['Timestamp'], timestamp_intervals)\n",
    "    df = df.dropna()\n",
    "\n",
    "    means_by_interval_df = df.groupby('Time interval').mean(numeric_only=True)\n",
    "    means_by_interval_df[independent_variable] = independent_variable_values\n",
    "    means_by_interval_df = means_by_interval_df.set_index(independent_variable)\n",
    "\n",
    "    return means_by_interval_df\n",
    "\n",
    "def combine_experiments(dfs, experiment_names):\n",
    "    metric_names = list(dfs[0].columns)\n",
    "\n",
    "    combined_df = None\n",
    "    for df, experiment_name in zip (dfs, experiment_names):\n",
    "        df.columns = [f'{experiment_name}:{col}' for col in df.columns]\n",
    "        if combined_df is None:\n",
    "            combined_df = df\n",
    "        else:\n",
    "            combined_df = combined_df.merge(df, left_index=True, right_index=True)\n",
    "    return combined_df, metric_names\n",
    "\n",
    "def plot_combined_experiments(combined_df, experiment_names, metric_names, kind='bar'):\n",
    "    for metric_name in metric_names:\n",
    "        column_names = [f'{experiment_name}:{metric_name}' for experiment_name in experiment_names]\n",
    "        ax = combined_df.plot(y=column_names, kind=kind)\n",
    "        if len(experiment_names) > 1:\n",
    "            ax.legend(experiment_names)\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "\n",
    "        title = \"Average \" if 'avg' in metric_name else \"Maximum \" if 'max' in metric_name else \"\"\n",
    "        title += \"Kepler\" if 'kepler' in metric_name else \"Prometheus\" if 'prometheus' in metric_name else \"\"\n",
    "        title += \" CPU\" if 'cpu' in metric_name else \" Network\" if 'network' in metric_name else \" Memory\" if 'memory' in metric_name else \"\"\n",
    "        title += \" Overhead\"\n",
    "        title += \" (transmitted)\" if 'transmit' in metric_name else \" (received)\" if 'receive' in metric_name else \"\"\n",
    "        ax.set_title(title)\n",
    "\n",
    "        if 'cpu' in metric_name:\n",
    "            ax.set_ylabel('%CPU Utilization')\n",
    "        elif 'network-transmit' in metric_name:\n",
    "            ax.set_ylabel('KiB/s Transmitted')\n",
    "        elif 'network-receive' in metric_name:\n",
    "            ax.set_ylabel('KiB/s Received')\n",
    "        elif 'memory' in metric_name:\n",
    "            ax.set_ylabel('MiB')\n",
    "\n",
    "def plot_experiments(result_directories, experiment_names, skip_memory=True, kind='bar'):\n",
    "    if type(result_directories) is not list and type(experiment_names) is not list:\n",
    "        result_directories = [result_directories]\n",
    "        experiment_names = [experiment_names]\n",
    "    if len(result_directories) != len(experiment_names):\n",
    "        print(\"Error: len(result_directories) != len(experiment_names). You must provide an experiment name for each result directory passed\")\n",
    "        return None\n",
    "    dfs = []\n",
    "    for result_directory in result_directories:\n",
    "        experiment_df = read_experiment(result_directory, skip_memory=skip_memory)\n",
    "        dfs.append(experiment_df)\n",
    "    combined_df, metric_names = combine_experiments(dfs, experiment_names)\n",
    "    plot_combined_experiments(combined_df, experiment_names, metric_names, kind=kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default these directories will be saved in: _output/results/\n",
    "directory1 =\n",
    "exeriment_name1 =\n",
    "\n",
    "directory2 =\n",
    "exeriment_name2 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single experiment\n",
    "result_directories = directory1\n",
    "experiment_names = exeriment_name1\n",
    "plot_experiments(result_directories, experiment_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple experiments on the same plots\n",
    "result_directories = [directory1, directory2]\n",
    "experiment_names = [exeriment_name1, exeriment_name2]\n",
    "plot_experiments(result_directories, experiment_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
